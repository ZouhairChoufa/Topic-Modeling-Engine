{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZfYiwnUnoA6UMt6QbOVgJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Install and Download Dependencies"],"metadata":{"id":"s-cYuDNBVKeY"}},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpSTzdeJVEyv","executionInfo":{"status":"ok","timestamp":1752178805525,"user_tz":-60,"elapsed":29521,"user":{"displayName":"Zouhair Choufa","userId":"11911449973679651299"}},"outputId":"72ef2a39-71fd-4a55-d6f3-3c33cb52cc00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Collecting fr-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["!pip install spacy scikit-learn requests beautifulsoup4 matplotlib langdetect\n","\n","# Download SpaCy language models for French and English\n","!python -m spacy download fr_core_news_sm\n","!python -m spacy download en_core_web_sm"]},{"cell_type":"markdown","source":["# Import Libraries and Configure Settings"],"metadata":{"id":"p_qX0t9MViTF"}},{"cell_type":"code","source":["import os\n","import pickle\n","import re\n","from concurrent.futures import ThreadPoolExecutor\n","\n","import matplotlib.pyplot as plt\n","import requests\n","import spacy\n","from bs4 import BeautifulSoup\n","from langdetect import LangDetectException, detect\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer,\n","                                             ENGLISH_STOP_WORDS)\n","from sklearn.metrics.pairwise import cosine_similarity\n","from spacy.lang.fr.stop_words import STOP_WORDS as FRENCH_STOP_WORDS\n","\n","# Load NLP models\n","nlp_fr = spacy.load(\"fr_core_news_sm\")\n","nlp_en = spacy.load(\"en_core_web_sm\")\n","\n","# URLs to index initially\n","target_urls = [\n","    \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\",\n","    \"https://fr.wikipedia.org/wiki/Apprentissage_automatique\",\n","    \"https://fr.wikipedia.org/wiki/Apprentissage_supervisé\",\n","    \"https://fr.wikipedia.org/wiki/Apprentissage_profond\",\n","    \"https://fr.wikipedia.org/wiki/Cybersécurité\",\n","    \"https://fr.wikipedia.org/wiki/Cybercriminalité\",\n","    \"https://fr.wikipedia.org/wiki/Système_d'exploitation\",\n","    \"https://fr.wikipedia.org/wiki/Réseau_informatique\",\n","    \"https://fr.wikipedia.org/wiki/Programmation_orientée_objet\",\n","    \"https://fr.wikipedia.org/wiki/Base_de_données\",\n","    \"https://fr.wikipedia.org/wiki/Cloud_computing\",\n","    \"https://fr.wikipedia.org/wiki/Big_data\",\n","    \"https://fr.wikipedia.org/wiki/Algorithme\"\n","]\n"],"metadata":{"id":"qru5JWeiVk58"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define Data Fetching and Processing Functions"],"metadata":{"id":"NXq3SdtMVrwn"}},{"cell_type":"code","source":["def get_text_from_url(url):\n","    \"\"\"Récupère et extrait le texte brut d'une URL.\"\"\"\n","    try:\n","        response = requests.get(url, timeout=15, headers={'User-Agent': 'Mozilla/5.0'})\n","        response.raise_for_status()\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        paragraphs = soup.find_all('p')\n","        return ' '.join([para.get_text() for para in paragraphs])\n","    except requests.RequestException as e:\n","        print(f\"Erreur lors de la récupération de l'URL {url}: {e}\")\n","        return \"\"\n","\n","def fetch_all_texts(urls):\n","    \"\"\"Télécharge le texte d'une liste d'URLs en parallèle.\"\"\"\n","    with ThreadPoolExecutor(max_workers=5) as executor:\n","        return list(executor.map(get_text_from_url, urls))\n","\n","def detect_language(text):\n","    \"\"\"Détecte la langue d'un extrait de texte donné.\"\"\"\n","    try:\n","        return detect(text[:500])\n","    except LangDetectException:\n","        return 'unknown'\n","\n","def clean_and_lemmatize_text(text):\n","    \"\"\"Nettoie et lemmatise le texte en utilisant le modèle de langue approprié.\"\"\"\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = re.sub(r'[^a-zA-ZÀ-ÿ\\s]', '', text)\n","    lang = detect_language(text)\n","    nlp = nlp_fr if lang == 'fr' else nlp_en\n","    doc = nlp(text.lower())\n","    return ' '.join([\n","        token.lemma_ for token in doc\n","        if token.text not in combined_stop_words and not token.is_punct and not token.is_space\n","    ])\n","\n","# Fonctions de mise en cache\n","def save_cache(data, filename):\n","    with open(filename, \"wb\") as f:\n","        pickle.dump(data, f)\n","\n","def load_cache(filename):\n","    if os.path.exists(filename):\n","        with open(filename, \"rb\") as f:\n","            return pickle.load(f)\n","    return None\n","\n","print(\"✅ Les fonctions utilitaires pour le traitement des données et la mise en cache sont définies.\")"],"metadata":{"id":"uhFvoxnhVt0B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define Model and Search Functions"],"metadata":{"id":"TEgqGkvBVy8s"}},{"cell_type":"code","source":["def build_tfidf_model(docs):\n","    \"\"\"Construit et retourne un vectoriseur TF-IDF et la matrice correspondante.\"\"\"\n","    vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, ngram_range=(1, 2))\n","    matrix = vectorizer.fit_transform(docs)\n","    return vectorizer, matrix\n","\n","def build_lda_model(docs, n_topics=4):\n","    \"\"\"Construit un modèle LDA et son vectoriseur correspondant.\"\"\"\n","    # Convertir le frozenset en liste pour le paramètre stop_words\n","    count_vectorizer = CountVectorizer(max_df=0.90, min_df=2, stop_words=list(combined_stop_words))\n","    count_matrix = count_vectorizer.fit_transform(docs)\n","    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n","    lda.fit(count_matrix)\n","    return lda, count_vectorizer\n","\n","def search_tfidf(query, vectorizer, matrix, urls, docs, top_n=10):\n","    \"\"\"Effectue une recherche en utilisant un modèle TF-IDF pré-calculé.\"\"\"\n","    cleaned_query = clean_and_lemmatize_text(query)\n","    query_vec = vectorizer.transform([cleaned_query])\n","    cosine_sim = cosine_similarity(query_vec, matrix).flatten()\n","    ranked_indices = cosine_sim.argsort()[::-1]\n","    results = []\n","    for i in ranked_indices:\n","        if cosine_sim[i] > 0 and len(results) < top_n:\n","            results.append((urls[i], docs[i][:250], cosine_sim[i]))\n","    return results\n","\n","print(\"✅ Les fonctions pour construire les modèles et effectuer la recherche sont définies.\")"],"metadata":{"id":"MXKeHt6PV0Pj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define Visualization Functions"],"metadata":{"id":"RhxTmD-sV7Bj"}},{"cell_type":"code","source":["def plot_tfidf_scores(results):\n","    \"\"\"Visualise les résultats de la recherche TF-IDF sous forme de diagramme à barres horizontales.\"\"\"\n","    if not results:\n","        print(\"Aucun résultat pertinent à afficher.\")\n","        return\n","    urls = [os.path.basename(result[0]) for result in results]\n","    scores = [result[2] for result in results]\n","    plt.figure(figsize=(12, 8))\n","    plt.barh(urls, scores, color='skyblue')\n","    plt.xlabel('Score de similarité')\n","    plt.ylabel('Document')\n","    plt.title('Scores de similarité TF-IDF pour la requête')\n","    plt.gca().invert_yaxis()\n","    plt.tight_layout()\n","    plt.show()\n","\n","def plot_lda_topics(model, vectorizer, n_top_words=10):\n","    \"\"\"Visualise les mots les plus importants pour chaque topic du modèle LDA.\"\"\"\n","    feature_names = vectorizer.get_feature_names_out()\n","    fig, axes = plt.subplots(model.n_components, 1, figsize=(10, 15), sharex=True)\n","    axes = axes.flatten()\n","    for topic_idx, topic in enumerate(model.components_):\n","        top_features_ind = topic.argsort()[-n_top_words:]\n","        top_features = feature_names[top_features_ind]\n","        weights = topic[top_features_ind]\n","        ax = axes[topic_idx]\n","        ax.barh(top_features, weights, height=0.7)\n","        ax.set_title(f\"Sujet #{topic_idx + 1}\", fontdict={\"fontsize\": 14})\n","        ax.invert_yaxis()\n","        ax.tick_params(axis='both', which='major', labelsize=12)\n","    plt.suptitle(\"Mots principaux par topic (LDA)\", fontsize=18)\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n","    plt.show()\n","\n","print(\"✅ Les fonctions de visualisation sont définies.\")"],"metadata":{"id":"OF_m9lX5V7XX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run the Main Program"],"metadata":{"id":"S8D1CZZNWIfJ"}},{"cell_type":"code","source":["# --- Chargement et Indexation des Données ---\n","CACHE_FILE = \"cached_data.pkl\"\n","cached_data = load_cache(CACHE_FILE)\n","\n","if cached_data:\n","    print(\"Chargement des données pré-traitées depuis le cache...\")\n","    documents, urls = cached_data\n","else:\n","    print(\"Récupération et traitement des documents depuis le web...\")\n","    raw_documents = fetch_all_texts(target_urls)\n","    successful_urls = [url for i, url in enumerate(target_urls) if raw_documents[i]]\n","    raw_documents = [doc for doc in raw_documents if doc]\n","\n","    # Définir les mots vides (stop words) combinés\n","    combined_stop_words = ENGLISH_STOP_WORDS.union(FRENCH_STOP_WORDS)\n","\n","    print(\"Nettoyage et lemmatisation des textes (cela peut prendre un moment)...\")\n","    documents = [clean_and_lemmatize_text(doc) for doc in raw_documents]\n","\n","    save_cache((documents, successful_urls), CACHE_FILE)\n","    urls = successful_urls\n","\n","print(f\"\\n{len(documents)} documents indexés avec succès.\")\n","\n","# --- Entraînement des Modèles ---\n","print(\"Construction des modèles TF-IDF et LDA...\")\n","tfidf_vectorizer, tfidf_matrix = build_tfidf_model(documents)\n","lda_model, lda_vectorizer = build_lda_model(documents, n_topics=4)\n","print(\"Les modèles sont prêts. 🚀\")\n","\n","# --- Boucle Interactive de Recherche et d'Analyse ---\n","while True:\n","    print(\"\\n\" + \"=\"*50)\n","    query = input(\"Entrez votre requête (ou 'exit' pour quitter) : \")\n","    if query.lower() == \"exit\":\n","        break\n","\n","    # 1. Effectuer la recherche TF-IDF\n","    print(\"\\n--- Résultats de la recherche TF-IDF ---\")\n","    tfidf_results = search_tfidf(query, tfidf_vectorizer, tfidf_matrix, urls, documents)\n","\n","    if not tfidf_results:\n","        print(\"Aucun document correspondant à votre requête n'a été trouvé.\")\n","        continue\n","\n","    for url, snippet, score in tfidf_results:\n","        print(f\"URL : {url} (Score : {score:.4f})\")\n","        print(f\"   Extrait : {snippet}...\\n\")\n","\n","    # 2. Visualiser les résultats TF-IDF\n","    print(\"\\n--- Visualisation des scores TF-IDF ---\")\n","    plot_tfidf_scores(tfidf_results)\n","\n","    # 3. Afficher et visualiser les sujets LDA\n","    print(\"\\n--- Résultats de la modélisation de topic (LDA) ---\")\n","    print(\"Voici les principaux topic trouvés dans l'ensemble des documents indexés.\")\n","    plot_lda_topics(lda_model, lda_vectorizer)\n","\n","    # 4. Analyse Comparative\n","    print(\"\\n---  Analyse Comparative ---\")\n","    print(f\"La recherche TF-IDF a trouvé des documents spécifiquement pertinents pour votre requête : '{query}'.\")\n","    print(\"Le modèle LDA montre les thèmes généraux présents dans l'ensemble de la collection de documents.\")\n","    print(\"En les comparant, vous pouvez voir si le document le plus pertinent pour votre requête correspond à l'un des topic principaux.\")"],"metadata":{"id":"ZBGbRG27WFMB"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"22d49346"},"source":[],"execution_count":null,"outputs":[]}]}